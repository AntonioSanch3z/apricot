{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    APRICOT: Advanced Platform for Reproducible Infrastructures in the Cloud via Open Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provide a complete example of reproducible experimentation in the field of life sciences. The objective is to determine the best reconstruction parameters for a simulated Positron Emission Tomography (PET) scanner system. For that purpose, the source code of two required programs has been distributed with this notebook. The first one, \"reconstructor\" is an implementation based on the OPLM algorithm for image reconstruction of PET systems. The second, \"evaluateImage\", gets a reconstructed image as input and compares it with the expected one and returns a set of image quality parameters. The input data is a simulated acquisition of a PET system formed by 3 rings with 20 detector modules each one. The simulated data has been provided via a public S3 bucket (https://s3.amazonaws.com/grycap/datasets/apricot/reconstruction/data.txz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medical scanners, like most physical detectors, measure raw data that must be post-processed to obtain an interpretable result. In particular, for medical scanners based in Positron Emission Tomography (PET) or Computed Tomography (CT), the final result is, usually, a patient image to be interpreted by the physician to develop a diagnostic. \n",
    "\n",
    "Focusing on PET and CT cases, there exists a great variety of iterative and analytic image reconstruction algorithms [0][1] [2][3], most of them based on maximum likelihood method [4].  These reconstruction algorithms have a set  of  variable  parameters  such  as  number  and  size  of  voxels  in  the  Field  Of View (FOV), number of iterations, number of partitioned data chunks, weight parameters, filter iterations and weight, etc.  Obviously, the final reconstruction quality  and  speed  will  depend  on  how  accurate  are  the  selected  parameters. Furthermore, the accuracy of selected parameters depend on the scanner system (geometry, energy resolution, scanned object, etc.).  Indeed, the importance of reconstruction parameters on medical image has been studied for different kind of scanners in many publications, such as [5] [6] [7] [8].\n",
    "\n",
    "Achieving the best parameters for our specific system and algorithm is desirable not only for medical diagnostics but to perform accurate comparison of reconstruction methods and scanner capabilities. That comparison is crucial to select and create new scanner systems using simulated data to study their theoretical performance. However, the number of possible parameters combinations grows as indicated in (1).\n",
    "\n",
    "\\begin{equation}\n",
    "\\prod_{i=1}^{n_{param}} N_i\\;,\n",
    "\\end{equation}\n",
    "\n",
    "where $N_i$ is the number of possible values of parameter number $i$ and $n_{param}$ the number of variable parameters. So, even performing a multiparametric study with few parameters requires a significant computational effort. APRICOT has been used in this experimentation to deploy and manage the required infrastructure to perform a multiparametric study on a modified implementation of \"OPL-EM\" reconstruction algorithm for PET systems described in the work by Reader et al. [1]. \n",
    "\n",
    "The input data used for this experimentation has been obtained simulating a PET system formed by three rings of $20$ detector modules each one. The simulations have been done using a self developed routines to perform PET system simulations with the Monte-Carlo (MC) code PENELOPE [9]. We will measure the reconstruction time and a set of quality metrics to determine the best parameters to achieve the required agreement between time spent for reconstruction and image quality. This metrics are, \"Root-Mean-Square Error\" (RMSE), \"Peak Signal to Noise Ratio\" (PSNR), \"Normalized Root Mean Square Distance\" (NRMSD) and \"Normalized Mean Absolute Distance\" (NMAD), which equations are listed below,\n",
    "\n",
    "\\begin{equation}\n",
    "    RMSE = \\sqrt{\\frac{1}{N} \\sum_{m=1}^{N} (v(m) - v_{true}(m))^{2}}\n",
    "    \\label{eq:RMSE}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    PSNR = 10 \\cdot log_{10}\\left( \\frac{\\max(v_{true})^2}{\\frac{1}{N} \\sum_{m=1}^{N} (v(m) -     v_{true}(m))^{2}}\\right) \n",
    "    \\label{eq:PSNR}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    NRMSD = \\sqrt{\\frac{\\sum_{m=1}^{N} (v(m) - v_{true}(m))^{2}}{\\sum_{m=1}^{N} (\\bar{v}_{true} - v_{true}(m))^{2}}}\n",
    "    \\label{eq:NRMSD}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    NMAD = \\frac{\\sum_{m=1}^{N} |v(m) - v_{true}(m)|}{\\sum_{m=1}^{N} |v_{true} (m)|}\n",
    "    \\label{eq:NMAD}\n",
    "\\end{equation}\n",
    "\n",
    "At metric equations, $v(m)$ denotes the voxel number $m$ of the considered image and the subindex $true$ indicate that is the real image. In this example we will plot the reconstruction time and the RMSE, but editing the code any metric can be ploted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experimentation we need to perform a multiparametric analysis to obtain the best image reconstruction parameters. So, the first step is infrastructure deployment. The chosen infrastructure is a batch cluster with 5 working nodes and ubuntu 18.04 LTS images as OS. Working nodes have 2 GB of RAM and 20 GB of disk space. Also, we recommend to assign, at least, two CPUs to the front-end node for this experiment. To reproduce the experiment deploy this infrastructure using the APRICOT deploy extension in one of the supported Cloud providers. You will need valid access credentials to your Cloud provider. Once the cluster has been configured, you can follow the experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the cluster and user names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterName = \"reconstruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"ubuntu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the python module with the APRICOT magics to manage our clusters. This step can be avoided if the module is loaded by default on each notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext apricot_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the infrastructure has been deployed and configured, check it using %apricot_ls magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%apricot_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the infrastructure deployment fails, we can get the output log with the following instruction,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot_log $clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data and programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we must provide the necessary data and software for our analisys:\n",
    "\n",
    "1- Raw simulated data\n",
    "\n",
    "2- Comparision program code\n",
    "\n",
    "3- Reconstruction program code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All required source codes can be upload easily from our computer using the ''%apricot_upload'' instruction. However, the input data with raw scanner simulated detections is stored externally because of its size. These data has been stored in a public Amazon S3 bucket and, thus, it can be downloaded using \"curl\". First, check if the \"input\" folder is at the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This folder contains the source codes, upload them to the front-end node of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot_upload $clusterName input /home/$username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the input data to the front-end node of the cluster using \"curl\". This step may take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName curl https://s3.amazonaws.com/grycap/datasets/apricot/reconstruction/data.txz --output data.txz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, extract the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName tar -xvf data.txz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all required files are in the \"input\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName ls input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to compile the source codes. All the necessary compilers and cmake tools should be installed at configuration initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the reconstruction and comparision programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName cd input/reconstructor_code && bash install.sh && cp reconstructor ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName cd input && g++ -o evaluateImage evaluateImage.cpp -O2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the executables have been created (evaluateImage and reconstructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName ls input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the necessary files at cluster. This has been configured automatically with NFS, so the '/home' directory is shared by all the working nodes and the front-end node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need also a folder to store the results. Create a folder named 'results' for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName mkdir results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to execute the computational experiment. For simplicity, this multiparametric study only uses three variable parameters. However, this can be extended to any number of parameter ranges. First of all, we need to specify each parameter interval and step size. To avoid large execution times, we will use large step sizes for all ranges. With the provided ranges, the total number of executed jobs will be 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minNvox_xy = 20\n",
    "maxNvox_xy = 250\n",
    "stepNvox_xy = 50\n",
    "\n",
    "minNvox_z = 20\n",
    "maxNvox_z = 250\n",
    "stepNvox_z = 100\n",
    "\n",
    "nChunksMin = 5\n",
    "nChunksMax = 5\n",
    "chunkStep = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use %apricot_genMPid function to obtain an identifier for the specified ranges. We will use this identifier to repeat the experimentation keeping the results of previous runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = %apricot_genMPid $minNvox_xy $maxNvox_xy $stepNvox_xy $minNvox_z $maxNvox_z $stepNvox_z $nChunksMin $nChunksMax $chunkStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a specific folder for this run with the previous ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName mkdir results/$ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName ls results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the jobs using ''%apricot_runMP'' and the local script ''script.sh''. This step can be delayed several minutes until all workers have been configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%apricot_runMP $clusterName script.sh /home/$username $minNvox_xy $maxNvox_xy $stepNvox_xy $minNvox_z $maxNvox_z $stepNvox_z $nChunksMin $nChunksMax $chunkStep\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all the jobs have been finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot exec $clusterName squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When no jobs appear in the tasks queue, execute post-processing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%apricot exec $clusterName bash input/getResults.sh $ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the results of our multiparametric study have been processed, download them to plot the corresponding graphs using \"%apricot_download\" instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFilename = \"results-\" + ID + \".dat\"\n",
    "%apricot_download $clusterName $resultsFilename ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and parse the results file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileIn = open(resultsFilename,\"r\")\n",
    "\n",
    "data = fileIn.read()\n",
    "\n",
    "# Extract data lines\n",
    "data = data.strip().split('\\n')\n",
    "# Remove header line\n",
    "data.pop(0)\n",
    "\n",
    "# Extract input data\n",
    "XYnvox = []\n",
    "Znvox = []\n",
    "chunks = []\n",
    "userTimeMin = []\n",
    "userTimeSec = []\n",
    "systemTimeMin = []\n",
    "systemTimeSec = []\n",
    "RMSE = []\n",
    "PSNR = []\n",
    "NRMSD = []\n",
    "NMAD = []\n",
    "\n",
    "for line in data:\n",
    "    line = \" \".join(line.split())\n",
    "    words = line.strip().split(' ')\n",
    "    XYnvox.append(float(words[0]))\n",
    "    Znvox.append(float(words[1]))\n",
    "    chunks.append(float(words[2]))\n",
    "    userTimeMin.append(float(words[3]))\n",
    "    userTimeSec.append(float(words[4]))\n",
    "    systemTimeMin.append(float(words[5]))\n",
    "    systemTimeSec.append(float(words[6]))\n",
    "    RMSE.append(float(words[7]))\n",
    "    PSNR.append(float(words[8]))\n",
    "    NRMSD.append(float(words[9]))\n",
    "    NMAD.append(float(words[10]))\n",
    "    \n",
    "    \n",
    "fileIn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the numpy and plot libraries. If the required packages are not installed in your system, execute the following statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 -m pip install --user numpy scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "userTime = np.add(np.multiply(userTimeMin,60.0),userTimeSec)\n",
    "systTime = np.add(np.multiply(systemTimeMin,60.0),systemTimeSec)\n",
    "totalTime = userTime + systTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nChunks = 5.0\n",
    "subXY = []\n",
    "subZ = []\n",
    "subTimes = []\n",
    "subRMSE = []\n",
    "subPSNR = []\n",
    "subNRMSD = []\n",
    "subNMAD = []\n",
    "\n",
    "subRMSE_zoom = []\n",
    "subXY_zoom = []\n",
    "subZ_zoom = []\n",
    "nVoxCut = 60\n",
    "\n",
    "for i in list(range(len(XYnvox))):\n",
    "    if nChunks == chunks[i]:\n",
    "        subXY.append(XYnvox[i])\n",
    "        subZ.append(Znvox[i])\n",
    "        subTimes.append(totalTime[i])\n",
    "        subRMSE.append(RMSE[i])\n",
    "        subPSNR.append(PSNR[i])\n",
    "        subNRMSD.append(NRMSD[i])\n",
    "        subNMAD.append(NMAD[i])\n",
    "        if XYnvox[i] > nVoxCut and Znvox[i] > nVoxCut:\n",
    "            subXY_zoom.append(XYnvox[i])\n",
    "            subZ_zoom.append(Znvox[i])\n",
    "            subRMSE_zoom.append(RMSE[i])\n",
    "        \n",
    "Axpad = 280        \n",
    "fig = plt.figure()\n",
    "#plt.rcParams[\"figure.figsize\"] = [100,100]\n",
    "#plt.rcParams.update({'font.size': 128})\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('nº voxels x-y')\n",
    "ax.set_ylabel('nº voxels z')\n",
    "ax.set_zlabel('time (s)')\n",
    "\n",
    "ax.xaxis.labelpad = Axpad\n",
    "ax.yaxis.labelpad = Axpad\n",
    "ax.zaxis.labelpad = Axpad\n",
    "\n",
    "\n",
    "ax.plot_trisurf(subXY,subZ,subTimes)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('nº voxels x-y')\n",
    "ax.set_ylabel('nº voxels z')\n",
    "ax.set_zlabel('rmse')\n",
    "\n",
    "ax.xaxis.labelpad = Axpad\n",
    "ax.yaxis.labelpad = Axpad\n",
    "ax.zaxis.labelpad = Axpad\n",
    "\n",
    "ax.plot_trisurf(subXY,subZ,subRMSE)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('nº voxels x-y')\n",
    "ax.set_ylabel('nº voxels z')\n",
    "ax.set_zlabel('rmse')\n",
    "\n",
    "ax.xaxis.labelpad = Axpad\n",
    "ax.yaxis.labelpad = Axpad\n",
    "ax.zaxis.labelpad = Axpad\n",
    "\n",
    "ax.plot_trisurf(subXY_zoom,subZ_zoom,subRMSE_zoom)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous graphs show the RMSE and reconstruction time for each parameter combination used in our study. In a real case study, these results should provide the best parameters to achieve the required agreement between reconstruction speed and image quality. However this is only a simplified example to show APRICOT functionality. Now, we can repeat the experiment with different parameter ranges or plot different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished the experimentation, do not forget to destroy the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apricot destroy $clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document includes infrastructure specifications, data storage, experimentation execution, results gathering and infrastructure termination for a example computational experimentation. Thus it can be reproduced easily distributing the experimentation notebook together with the required source codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0] Xuan Liu, Claude Comtat, Christian Michel, Paul Kinahan, Michel Defrise, and David Townsend. Comparison of 3-d reconstruction with 3d-osem and with fore + osem for pet. IEEE TRANSACTIONS ON MEDICAL IMAGING, 2001\n",
    "\n",
    "[1]  Andrew  J.  Reader,   Stijn  Ally,   Filippos  Bakatselos,   Roido  Manavaki, Richard J. Walledge, Alan P. Jeavons, Peter J. Julyan, Sha Zhao, David L. Hastings, and Jamal Zweit.  One-pass list-mode em algorithm for high-resolution 3-d pet image reconstruction into large arrays. IEEE  TRANSACTIONS ON NUCLEAR SCIENCE, 2002.\n",
    "\n",
    "[2]  Sarabjeet Singh, Mannudeep K. Kalra, Jiang Hsieh, Paul E. Licato, Synho Do, Homer H. Pien, Michael A. Blake. Abdominal ct: Comparison of adaptive  statistical  iterative  and  filtered  back  projection  reconstruction  techniques. Radiology, 2010.\n",
    "\n",
    "[3] Chillarón,  Mónica.,  Vidal,  Vicent,  Verdú,  Gumersindo. Ct  image  reconstruction withsuitesparseqr factorization package. Radiation  Physics  and Chemistry, 2019.\n",
    "\n",
    "[4] L.A. Sheep and Y.Vardi.  Maximum likelihood reconstruction for emission tomography. IEEE TRANSACTIONS ON MEDICAL IMAGING, 1982.\n",
    "\n",
    "[5] Jin Mo Goo, Trongtum Tongdee, Ranista Tongdee, Kwangjae Yeo, Charles F. Hildebolt, Kyongtae T. Bae. Volumetric measurement of synthetic lung nodules  with  multi–detector  row  ct:  Effect  of  various  image  reconstruction  parameters  and  segmentation  thresholds  on  measurement  accuracy. Radiology, 2005.\n",
    "\n",
    "[6] James  G.  Ravenel,  William  M.  Leue,  Paul  J.  Nietert,  James  V.  Miller, Katherine K. Taylor, Gerard A. Silvestri.  Pulmonary nodule volume:  Effects of reconstruction parameters on automated measurements—a phantom study. Radiology, 2008.\n",
    "\n",
    "[7] Yue-Houng Hu, Bo Zhao, Wei Zhao.  Image artifacts in digital breast tomosynthesis:  Investigation  of  the  effects  of  system  geometry  and  reconstruction  parameters  using  a  linear  system  approach. Medical  Physics, 2008.\n",
    "\n",
    "[8] Maria Lyra, Agapi Ploussi. Filtering in spect image reconstruction. Journal of Biomedical Imaging, 2011.\n",
    "\n",
    "[9] Salvat F. Penelope. a code system for monte carlo simulation of electron and photon transport. Issy-Les-Moulineaux: OECD  Nuclear  Energy  Agengy, 2014."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
